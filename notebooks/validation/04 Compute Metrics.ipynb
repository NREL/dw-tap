{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f59f1c2",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "\n",
    "Caleb Phillips (caleb.phillips@nrel.gov) and Jenna Ruzekowicz (jenna.ruzekowicz@nrel.gov)\n",
    "\n",
    "The purpose of this notebook is to read in computed predictions and compare them to actual observations, computing metrics. We will compute metrics and produce the summary files:\n",
    "\n",
    "> error_metrics_summary_wtk|wtk_led_2019|wtk_led_2018.csv\n",
    "  \n",
    "> provider,site,height_m,model,metric,value\n",
    "\n",
    "***FIXME: height is not carried over in model output\n",
    "  \n",
    "And, hour, month, sector summaries:\n",
    "\n",
    "> results_hms_{metric}.csv\n",
    "  \n",
    "> provider,site,height_m,model,hour,month,sector_deg,value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c63dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import re\n",
    "from dw_tap.power_output import estimate_power_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bf113c-ae52-4403-b070-4cbb55d7ad4f",
   "metadata": {},
   "source": [
    "## ANL WTK-LED 2019, no BC, FIXME: Does this include vegetation or no?? Ask Dmitry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a6c121-bd2f-4c76-a933-6f5cebe2df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime        ws          wd  \\\n",
      "0      2007-01-01 00:00:00  7.516921  221.320538   \n",
      "1      2007-01-01 01:00:00  7.535241  222.903415   \n",
      "2      2007-01-01 02:00:00  7.157962  223.277353   \n",
      "3      2007-01-01 03:00:00  5.766696  216.183644   \n",
      "4      2007-01-01 04:00:00  7.140035  229.592219   \n",
      "...                    ...       ...         ...   \n",
      "61363  2013-12-31 19:00:00  2.051973  205.166430   \n",
      "61364  2013-12-31 20:00:00  2.524148  184.089366   \n",
      "61365  2013-12-31 21:00:00  3.818210  177.280255   \n",
      "61366  2013-12-31 22:00:00  3.387345  167.183998   \n",
      "61367  2013-12-31 23:00:00  4.431360  154.608806   \n",
      "\n",
      "       inversemoninobukhovlength_2m   tid                packet_date  \\\n",
      "0                          0.010078  t183  2007-01-01 00:00:00+00:00   \n",
      "1                          0.008616  t183  2007-01-01 01:00:00+00:00   \n",
      "2                          0.011590  t183  2007-01-01 02:00:00+00:00   \n",
      "3                          0.020440  t183  2007-01-01 03:00:00+00:00   \n",
      "4                          0.009630  t183  2007-01-01 04:00:00+00:00   \n",
      "...                             ...   ...                        ...   \n",
      "61363                     -0.142545  t183  2013-12-31 19:00:00+00:00   \n",
      "61364                     -0.072874  t183  2013-12-31 20:00:00+00:00   \n",
      "61365                     -0.009379  t183  2013-12-31 21:00:00+00:00   \n",
      "61366                      0.088808  t183  2013-12-31 22:00:00+00:00   \n",
      "61367                      0.078850  t183  2013-12-31 23:00:00+00:00   \n",
      "\n",
      "       ws-adjusted  \n",
      "0         7.516924  \n",
      "1         7.535244  \n",
      "2         7.157964  \n",
      "3         5.766700  \n",
      "4         7.140035  \n",
      "...            ...  \n",
      "61363     2.051974  \n",
      "61364     2.524153  \n",
      "61365     3.818220  \n",
      "61366     3.388905  \n",
      "61367     4.732514  \n",
      "\n",
      "[61368 rows x 7 columns]\n",
      "       tid                packet_date         ws          wd  \\\n",
      "0     t041  2019-01-01 00:00:00+00:00  11.860750    4.662364   \n",
      "1     t041  2019-01-01 01:00:00+00:00  12.296127    6.648272   \n",
      "2     t041  2019-01-01 02:00:00+00:00  12.480973    6.648769   \n",
      "3     t041  2019-01-01 03:00:00+00:00  13.406009    9.744094   \n",
      "4     t041  2019-01-01 04:00:00+00:00  11.599450    2.889605   \n",
      "...    ...                        ...        ...         ...   \n",
      "8755  t041  2019-12-31 19:00:00+00:00   9.919707  304.775177   \n",
      "8756  t041  2019-12-31 20:00:00+00:00   9.065367  300.051981   \n",
      "8757  t041  2019-12-31 21:00:00+00:00   9.598501  302.157367   \n",
      "8758  t041  2019-12-31 22:00:00+00:00   9.149601  304.370140   \n",
      "8759  t041  2019-12-31 23:00:00+00:00   8.059356  302.792617   \n",
      "\n",
      "                       datetime  ws-adjusted  \n",
      "0     2019-01-01 00:00:00+00:00    11.860750  \n",
      "1     2019-01-01 01:00:00+00:00    12.296127  \n",
      "2     2019-01-01 02:00:00+00:00    12.480973  \n",
      "3     2019-01-01 03:00:00+00:00    13.406009  \n",
      "4     2019-01-01 04:00:00+00:00    11.599450  \n",
      "...                         ...          ...  \n",
      "8755  2019-12-31 19:00:00+00:00     9.919707  \n",
      "8756  2019-12-31 20:00:00+00:00     9.065367  \n",
      "8757  2019-12-31 21:00:00+00:00     9.598501  \n",
      "8758  2019-12-31 22:00:00+00:00     9.149601  \n",
      "8759  2019-12-31 23:00:00+00:00     8.059356  \n",
      "\n",
      "[8760 rows x 6 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#Ground truth data comes from reversing the measured power output to windspeed\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m01 Bergey Turbine Data/prepared_and_combined.csv.bz2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m ground_truth\u001b[38;5;241m.\u001b[39mloc[ground_truth[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m tid]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#Merge the two data sources (ground truth and wtk-led predicted) into single dataframe\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1253\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1253\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/bz2.py:195\u001b[0m, in \u001b[0;36mBZ2File.read1\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    194\u001b[0m     size \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dw-tap/lib/python3.8/_compression.py:103\u001b[0m, in \u001b[0;36mDecompressReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         rawblock \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Empty dataframes to store the final metrics into\n",
    "error_dataframe_wtk_2019 = pd.DataFrame()\n",
    "\n",
    "#Directory path of model data \n",
    "directoryPath = \"03 Model Outputs/\"\n",
    "\n",
    "#For every file with model results (both wtk and wtk-led)\n",
    "for file in glob.glob(directoryPath + '*.csv.bz2'):\n",
    "    model_data_file = pd.read_csv(file)\n",
    "    \n",
    "    #If the file is a wtk_led file for 2019, we have hourly ws prediction data\n",
    "    if file.find(\"wtk_led_2019.csv\") != -1:\n",
    "        #Pull the turbine id from the name of the file\n",
    "        tid = re.search(\"_t[0-9]{3}_\", file).group().replace(\"_\", \"\")\n",
    "        model = \"lanl\"\n",
    "        \n",
    "        #Ground truth data comes from reversing the measured power output to windspeed\n",
    "        ground_truth = pd.read_csv(\"01 Bergey Turbine Data/prepared_and_combined.csv.bz2\")\n",
    "        ground_truth = ground_truth.loc[ground_truth[\"tid\"] == tid]\n",
    "        \n",
    "        #Merge the two data sources (ground truth and wtk-led predicted) into single dataframe\n",
    "        turbine_data = pd.DataFrame.merge(model_data_file, ground_truth, on=\"packet_date\")\n",
    "        turbine_data[\"error\"] = turbine_data[\"ws-adjusted\"] - turbine_data[\"windspeed_mps\"]\n",
    "        \n",
    "        #Bin timeseries data by hour, month, and sector\n",
    "        turbine_data['hour'] = turbine_data['packet_date'].astype('datetime64[ns]').dt.hour\n",
    "        turbine_data['month'] = turbine_data['packet_date'].astype('datetime64[ns]').dt.month\n",
    "        turbine_data['sector'] = sectorize(turbine_data['wd'])\n",
    "        \n",
    "        #Cuts out turbine ids with no ground truth data present (192 and 207 as of 4/16/23)\n",
    "        if len(turbine_data[\"windspeed_mps\"]) > 0:\n",
    "            error_metrics_dict = error_metrics(turbine_data[\"ws-adjusted\"], turbine_data[\"windspeed_mps\"])\n",
    "            error_metrics_dict[\"source\"] = \"wtk_led_2019\"\n",
    "            error_metrics_dict[\"tid\"] = tid\n",
    "            error_metrics_dict[\"model\"] = model\n",
    "            error_metrics_df = pd.DataFrame(error_metrics_dict, index=[0])\n",
    "            error_dataframe_wtk_2019 = pd.concat([error_dataframe_wtk_2019, error_metrics_df])\n",
    "            \n",
    "            #Visualizations\n",
    "            #Scatter and histogram plots for individual turbine ids error metrics\n",
    "            #plot_scatter_and_hist(turbine_data[\"ws-adjusted\"],turbine_data[\"windspeed_mps\"],tid = tid, axrange=[0,16])\n",
    "            \n",
    "            #Polar plot for individual turbine ids error metrics\n",
    "            #plotpolar(turbine_data)\n",
    "            \n",
    "            #12x24 heatmap for individual turbine ids error metrics\n",
    "            #heat_table = plot1224heatmap(turbine_data)\n",
    "            \n",
    "            #Save site-specific 12x24 summaries (heat_table), can only save if previous viz line is run\n",
    "            #heat_table.to_csv(\"04 Error Metrics/1224summary_wtk_led_2019_\" + tid + '_' + model + \".csv.bz2\")\n",
    "        \n",
    "\n",
    "#print(error_dataframe_wtk_2019)\n",
    "\n",
    "\n",
    "#Save error_dataframe_wtk_2019\n",
    "error_dataframe_wtk_2019.to_csv(\"04 Error Metrics/error_metrics_summary_wtk_led_2019.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98012c7-3a7d-4cac-af1e-c409335e1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dataframe_wtk = pd.DataFrame()\n",
    "#Directory path of model data \n",
    "directoryPath = \"03 Model Outputs/\"\n",
    "\n",
    "#For every file with model results (both wtk and wtk-led)\n",
    "for file in glob.glob(directoryPath + '*.csv.bz2'):\n",
    "    model_data_file = pd.read_csv(file)\n",
    "    \n",
    "    if file.find(\"wtk.csv\") != -1:\n",
    "        #Do processing for wtk data (<2018)\n",
    "        tid = re.search(\"_t[0-9]{3}_\", file).group().replace(\"_\", \"\")\n",
    "        if file.find(\"lanl\") != -1: model = \"lanl\"\n",
    "        elif file.find(\"anl\") != -1: model = \"anl\"\n",
    "        print(model_data_file)\n",
    "        #TODO: Read in the hourly ws data for the turbine and convert to power production\n",
    "        \n",
    "        \n",
    "        #TODO: Combine production data into sums for the daily values\n",
    "        \n",
    "        \n",
    "        #Read in the ground truth data for daily summaries \n",
    "        ground_truth = pd.read_csv(\"01 Bergey Turbine Data/daily_summaries.csv.bz2\")\n",
    "        #Get rid of everything that is before 2018\n",
    "        ground_truth = ground_truth[~(ground_truth['date'] >= '2017-12-31')]\n",
    "        \n",
    "        #TODO: Combine dataframes on date (by date)\n",
    "        \n",
    "        #TODO: Run error metrics for ground truth of day vs. wtk day\n",
    "        \n",
    "        print(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
