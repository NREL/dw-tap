{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d3dde6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run ANL's LOM: PILOWF\n",
    "\n",
    "Jenna Ruzekowicz (jenna.ruzekowicz@nrel.gov), Caleb Phillips (caleb.phillips@nrel.gov), and Dmitry Duplyakin (dmitry.duplyakin@nrel.gov)\n",
    "\n",
    "The purpose of this notebook is to read in inflow data, load obstacle data, and run the LOMs.\n",
    "\n",
    "Output is saved into files named:\n",
    "\n",
    " > `bergey|oneenergy_anl|lanl_tid_windSource_obstacleMode.csv.bz2`, \n",
    " \n",
    " > where `windSource` is one of: `wtk`, `wtk_led_2018`, `wtk_led_2019`, `wtk_bc`, `wtk_led_bc` (`bc` referes to bias corrected versions) \n",
    " \n",
    " > and `obstacleMode` is one of: `bldgsonly`, `treesasbldgs`, `bldgsandtrees`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075b7a5-56ac-4f9c-b8ae-c7777fdffdb1",
   "metadata": {},
   "source": [
    "### Work notes:\n",
    "\n",
    "- Currently only ANL model\n",
    "- Sites t007 and t074 are currently excluded becuase they don't have height data matching other sites\n",
    "- Code looks for `\"%s/%sv2.json\" % (obstacle_data_dir, tid)` files for site obstacles inside `02 Input For Models` dir\n",
    "- Sites t207 take a very long time! (slowest site)\n",
    "- Notice that based on the plots at the end of the notebook ws-adjusted = ws (exactly) for quite a few sites. No negative ws-adjusted values observed yet for this set of inputs.\n",
    "- `wind_sources = [\"wtk\", \"wtk_led_2019\", \"wtk_bc\", \"wtk_led_bc\"]` -- not including \"wtk_led_2018\" yet becuase 5-minuted data for 2018 is very large and processing will be slower than for other options here; will add it for final/more complete processing\n",
    "- `overwrite` (if not set) flag allows to skip processing previously studied site x wind_source combinations (if output files with matching names are found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532eb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dw_tap.lom import run_lom\n",
    "import os\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from dw_tap.data_processing import _LatLon_To_XY, filter_obstacles\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa688a-d76f-46e3-ba77-3106e048f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(\"01 Bergey Turbine Data/bergey_sites.csv\")\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d8b2e-d9ea-4996-a15f-72bd5abd11cc",
   "metadata": {},
   "source": [
    "### Select which sites need to be processed, wind data sources, and obstacles modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e211c-0da0-435e-9124-63caa9107d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small test with several sites\n",
    "#selected = [\"t133\", \"t135\"]\n",
    "#selected = [\"t034\", \"t133\", \"t135\"]\n",
    "#selected = [\"t207\"]\n",
    "\n",
    "# Process all sites:\n",
    "selected = index[\"APRS ID\"].tolist()\n",
    "\n",
    "# Remove 2 sites that currently don't have obstacle descriptions with the heights based on lidar data\n",
    "selected = [x for x in selected if not(x in [\"t007\", \"t074\"])]\n",
    "\n",
    "# Remove slowest site for now\n",
    "selected = [x for x in selected if not(x in [\"t207\"])]\n",
    "print(selected)\n",
    "\n",
    "wind_sources = [\"wtk\", \"wtk_bc\"] # Choices here: \"wtk\", \"wtk_led_2018\", \"wtk_led_2019\", \"wtk_bc\"\n",
    "\n",
    "obstacle_modes = [\"bldgsonly_100m\"] #\"bldgsonly_100m\"] #\"bldgsonly\", \"treesasbldgs\"] #, \"bldgsandtrees\"] # Choices here: `bldgsonly`, `bldgsandtrees`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec40ab5-38e0-49ee-a549-6c8578f5b8cc",
   "metadata": {},
   "source": [
    "### Load wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da36dd-aa59-43a4-9c75-38995b2d9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmospheric_inputs = {}\n",
    "\n",
    "for wind_source in wind_sources:\n",
    "\n",
    "    if wind_source == \"wtk\":\n",
    "\n",
    "        wtk_df = pd.read_csv(\"01 Bergey Turbine Data/wtk.csv.bz2\")\n",
    "\n",
    "        # Create dict with dataframes that correspond to selected tid's\n",
    "        dfs_by_tid = {}\n",
    "        for tid in selected:\n",
    "            dfs_by_tid[tid] = wtk_df[wtk_df[\"tid\"] == tid].reset_index(drop=True)\n",
    "            #display(dfs_by_tid[tid].head(3))\n",
    "        \n",
    "        atmospheric_inputs[wind_source] = dfs_by_tid\n",
    "\n",
    "    elif wind_source == \"wtk_led_2018\":\n",
    "\n",
    "        wtk_led_2018 = pd.read_csv(\"01 Bergey Turbine Data/wtk_led_2018.csv.bz2\")\n",
    "\n",
    "        # Create dict with dataframes that correspond to selected tid's\n",
    "        dfs_by_tid = {}\n",
    "        for tid in selected:\n",
    "            dfs_by_tid[tid] = wtk_led_2018[wtk_led_2018[\"tid\"] == tid].copy().reset_index(drop=True)\n",
    "            dfs_by_tid[tid][\"datetime\"] = dfs_by_tid[tid][\"packet_date\"]\n",
    "            #display(dfs_by_tid[tid].head(3))\n",
    "        \n",
    "        atmospheric_inputs[wind_source] = dfs_by_tid\n",
    "\n",
    "    elif wind_source == \"wtk_led_2019\":\n",
    "\n",
    "        wtk_led_2019 = pd.read_csv(\"01 Bergey Turbine Data/wtk_led_2019.csv.bz2\")\n",
    "\n",
    "        # Create dict with dataframes that correspond to selected tid's\n",
    "        dfs_by_tid = {}\n",
    "        for tid in selected:\n",
    "            dfs_by_tid[tid] = wtk_led_2019[wtk_led_2019[\"tid\"] == tid].copy().reset_index(drop=True)\n",
    "            dfs_by_tid[tid][\"datetime\"] = dfs_by_tid[tid][\"packet_date\"]\n",
    "            #display(dfs_by_tid[tid].head(3))\n",
    "            \n",
    "        atmospheric_inputs[wind_source] = dfs_by_tid\n",
    "\n",
    "    elif wind_source == \"wtk_bc\":\n",
    "        wtk_bc_df = pd.read_csv(\"02 Bias Correction/wtk_bc.csv.bz2\")\n",
    "        \n",
    "        # Create dict with dataframes that correspond to selected tid's\n",
    "        dfs_by_tid = {}\n",
    "        for tid in selected:\n",
    "            dfs_by_tid[tid] = wtk_bc_df[wtk_bc_df[\"tid\"] == tid].reset_index(drop=True)\n",
    "            \n",
    "            # Actually use bias corrected wind speeds for further steps (overwrite original ws)\n",
    "            dfs_by_tid[tid][\"ws\"] = dfs_by_tid[tid][\"ws_bc\"]\n",
    "            \n",
    "            #display(dfs_by_tid[tid].head(3))\n",
    "        \n",
    "        atmospheric_inputs[wind_source] = dfs_by_tid\n",
    "        \n",
    "    elif wind_source == \"wtk_led_bc\":\n",
    "        wtk_led_bc_df = pd.read_csv(\"02 Bias Correction/wtk_led_bc.csv.bz2\")\n",
    "        \n",
    "        # Create dict with dataframes that correspond to selected tid's\n",
    "        dfs_by_tid = {}\n",
    "        for tid in selected:\n",
    "            dfs_by_tid[tid] = wtk_led_bc_df[wtk_led_bc_df[\"tid\"] == tid].reset_index(drop=True)\n",
    "            \n",
    "            # Actually use bias corrected wind speeds for further steps (overwrite original ws)\n",
    "            dfs_by_tid[tid][\"ws\"] = dfs_by_tid[tid][\"ws_bc\"]\n",
    "            \n",
    "            #display(dfs_by_tid[tid].head(3))\n",
    "        \n",
    "        atmospheric_inputs[wind_source] = dfs_by_tid\n",
    "        \n",
    "    else:\n",
    "        print(\"Unsupported wind_source selected:\", wind_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14878556-c3d2-460d-b15d-1c68ba78b2b5",
   "metadata": {},
   "source": [
    "### Load obstacle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab492c6-2512-4efd-95bd-e038834a5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_with_tall_blgs = [] \n",
    "\n",
    "obstacle_inputs = {}\n",
    "for tid in selected:\n",
    "    #print(\"Processing tid: \", tid)\n",
    "    \n",
    "    index_row = index[index[\"APRS ID\"] == tid].iloc[0]\n",
    "    z_turbine = index_row[\"Hub Height (m)\"]\n",
    "    \n",
    "    obstacle_data_dir = \"01 Bergey Turbine Data/3dbuildings_geojson\"\n",
    "    obstacle_data_file = \"%s/%sv2.json\" % (obstacle_data_dir, tid)\n",
    "    \n",
    "    if os.path.exists(obstacle_data_file):\n",
    "        #print(\"BEFORE filtering (%s):\" % obstacle_data_file)\n",
    "        #display(gpd.read_file(obstacle_data_file))\n",
    "        \n",
    "        obstacle_df = filter_obstacles(tid,\n",
    "                                       gpd.read_file(obstacle_data_file), \n",
    "                                       include_trees=True, \n",
    "                                       turbine_height_for_checking=z_turbine)\n",
    "        obstacle_df[\"tid\"] = tid\n",
    "        obstacle_inputs[tid] = obstacle_df\n",
    "        \n",
    "        #print(\"AFTER filtering (%s):\" % obstacle_data_file)\n",
    "        #display(obstacle_df)\n",
    "    else:\n",
    "        print(\"Can't access: %s. Skipping\" % obstacle_data_file)\n",
    "\n",
    "all_obstacle_inputs = pd.concat(obstacle_inputs.values())\n",
    "display(all_obstacle_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11b87a-cc87-4fcb-9b18-3d1fc44d6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined and filtered obstacles dataframe into a file\n",
    "#obstacle_data_dir = \"01 Bergey Turbine Data/3dbuildings_geojson\"\n",
    "#dest_file = \"%s/all_obstacles.json\" % (obstacle_data_dir)\n",
    "#all_obstacle_inputs.to_file(dest_file, driver=\"GeoJSON\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013cbc2-1919-4691-a2fe-84cdc275d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick vis:\n",
    "for tid, obstacle_df in obstacle_inputs.items():\n",
    "    obstacle_df.plot(figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad491749-7b9b-4488-8f04-f021834fccf2",
   "metadata": {},
   "source": [
    "### Run ANL's LOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e38ca-2668-4df0-8bcc-c8781b696b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working sequential version -- one site at a time\n",
    "\n",
    "# # This flag allows overwriting previously saved files with results if they are found in the specified directory dest_dir \n",
    "# overwrite = False\n",
    "\n",
    "# # Will be used in the filenames\n",
    "# site_type = \"bergey\"\n",
    "\n",
    "# # Will be used in the filenames\n",
    "# model_type = \"anl\"\n",
    "\n",
    "# dest_dir = \"03 Model Outputs\"\n",
    "# if not os.path.exists(dest_dir):\n",
    "#     os.makedirs(dest_dir)    \n",
    "    \n",
    "# for tid in tqdm(selected):\n",
    "    \n",
    "#     for wind_source in wind_sources:\n",
    "        \n",
    "#         for obstacle_mode in obstacle_modes:\n",
    "        \n",
    "#             dest_filename = \"%s/%s_%s_%s_%s_%s.csv.bz2\" % (dest_dir, site_type, model_type, tid, wind_source, obstacle_mode)\n",
    "            \n",
    "#             if (not overwrite) and (os.path.exists(dest_filename)):\n",
    "#                 print(\"Found previously saved %s); overwrite flag is off. Skipping to next config.\" % (dest_filename))\n",
    "#             else:\n",
    "#                 row = index[index[\"APRS ID\"] == tid].iloc[0]\n",
    "#                 #print(row)\n",
    "#                 lat = row[\"Latitude\"]\n",
    "#                 lon = row[\"Longitude\"]\n",
    "#                 z_turbine = row[\"Hub Height (m)\"]\n",
    "#                 xy_turbine = [np.array([lon, lat])]\n",
    "\n",
    "#                 if obstacle_mode == \"bldgsonly\":\n",
    "#                     obs_df = obstacle_inputs[tid]\n",
    "#                     obs_df = obs_df[obs_df[\"feature_type\"] == \"building\"].reset_index(drop=True)\n",
    "#                 elif obstacle_mode == \"bldgsandtrees\":\n",
    "#                     # Assume trees pass the filtering run above in this notebook \n",
    "#                     obs_df = obstacle_inputs[tid]\n",
    "                \n",
    "#                 predictions_df = run_lom(atmospheric_inputs[wind_source][tid], \\\n",
    "#                                          obs_df, \\\n",
    "#                                          xy_turbine, z_turbine, \\\n",
    "#                                          check_distance=True)\n",
    "\n",
    "#                 # Add LOM output back to the more complete input dataframe\n",
    "#                 atmospheric_inputs[wind_source][tid][\"ws-adjusted\"] = predictions_df[\"ws-adjusted\"]   \n",
    "#                 atmospheric_inputs[wind_source][tid].to_csv(dest_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f69fa3-c287-4585-8db1-1a689959be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare files for PILOWF + multiprocessing & run LOM\n",
    "\n",
    "# This flag allows overwriting previously saved files with results if they are found in the specified directory dest_dir \n",
    "overwrite = True\n",
    "\n",
    "# Will be used in the filenames\n",
    "site_type = \"bergey\"\n",
    "\n",
    "# Will be used in the filenames\n",
    "model_type = \"anl\"\n",
    "\n",
    "dest_dir = \"01 Bergey Turbine Data/pilowf_inputs/\"\n",
    "\n",
    "script_path = \"./run_pilowf_mp.py\"\n",
    "    \n",
    "for wind_source in wind_sources:\n",
    "\n",
    "    for obstacle_mode in obstacle_modes:\n",
    "\n",
    "        # Make sure to start from scratch and not reuse previously saved inputs\n",
    "        if os.path.exists(dest_dir):\n",
    "            shutil.rmtree(dest_dir, ignore_errors=True)\n",
    "        os.makedirs(dest_dir)    \n",
    "        \n",
    "        for tid in selected:\n",
    "            row = index[index[\"APRS ID\"] == tid].iloc[0]\n",
    "            #print(row)\n",
    "            lat = row[\"Latitude\"]\n",
    "            lon = row[\"Longitude\"]\n",
    "            z_turbine = row[\"Hub Height (m)\"]\n",
    "            xy_turbine = [np.array([lon, lat])]\n",
    "\n",
    "            if obstacle_mode == \"bldgsonly\":\n",
    "                obs_df = obstacle_inputs[tid]\n",
    "                obs_df = obs_df[obs_df[\"feature_type\"] == \"building\"].reset_index(drop=True)\n",
    "            elif obstacle_mode == \"bldgsandtrees\":\n",
    "                # Assume trees pass the filtering run above in this notebook  \n",
    "                obs_df = obstacle_inputs[tid]\n",
    "            elif obstacle_mode == \"treesasbldgs\":\n",
    "                # Assume trees pass the filtering run above in this notebook \n",
    "                obs_df = obstacle_inputs[tid]  \n",
    "            elif obstacle_mode == \"bldgsonly_100m\":\n",
    "                # Assume trees pass the filtering run above in this notebook \n",
    "                obs_df = obstacle_inputs[tid].copy()\n",
    "\n",
    "                print(\"# of obs (before 100m filtering):\", len(obs_df))\n",
    "                obs_df = filter_obstacles(tid,\n",
    "                                          obs_df,\n",
    "                                          include_trees=False, \n",
    "                                          turbine_height_for_checking=z_turbine,\n",
    "                                          limit_to_radius_in_m=100.0,\n",
    "                                          turbine_lat_lon=(lat, lon))\n",
    "                print(\"# of obs (after 100m filtering):\", len(obs_df))\n",
    "                \n",
    "            elif obstacle_mode == \"treesasbldgs_100m\":\n",
    "                # Assume trees pass the filtering run above in this notebook \n",
    "                obs_df = obstacle_inputs[tid].copy()\n",
    "\n",
    "                print(\"# of obs (before 100m filtering):\", len(obs_df))\n",
    "                obs_df = filter_obstacles(tid,\n",
    "                                          obs_df,\n",
    "                                          include_trees=True, \n",
    "                                          turbine_height_for_checking=z_turbine,\n",
    "                                          limit_to_radius_in_m=100.0,\n",
    "                                          turbine_lat_lon=(lat, lon))\n",
    "                print(\"# of obs (after 100m filtering):\", len(obs_df))\n",
    "            \n",
    "            \n",
    "            if len(obs_df) == 0:\n",
    "                print(\"tid=%s: Obstacle set is empty after filtering. ws-adjusted=ws for this cases.\" % tid)\n",
    "            # obs_df.to_file() breaks if empty \n",
    "            \n",
    "                output_dest = \"03 Model Outputs/%s_%s_%s_%s_%s.csv.bz2\" % (site_type, model_type, tid, wind_source, obstacle_mode)\n",
    "                \n",
    "                if (not overwrite) and (os.path.exists(output_dest)):\n",
    "                    print(\"Found previously saved %s); overwrite flag is off. Skipping to next config.\" % (dest_filename))\n",
    "                else:\n",
    "                    res = atmospheric_inputs[wind_source][tid].copy()\n",
    "                    res[\"ws-adjusted\"] = res[\"ws\"]\n",
    "                    #res.to_csv(output_dest, index=False)  \n",
    "                    print(\"Saved output:\", output_dest)\n",
    "\n",
    "                # Skip the following and go to the next tid x obstacle_mode combination\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Save inputs for PILOWF into separate files\n",
    "            obs_df.to_file(\"%s/%s-obstacles.json\" % (dest_dir, tid),\\\n",
    "                           driver=\"GeoJSON\", index=False)\n",
    "            atmospheric_inputs[wind_source][tid].to_csv(\"%s/%s-atmospheric.csv.bz2\" % (dest_dir, tid), index=False)\n",
    "        \n",
    "        # It is expecteed that inputs_dir now has a set of individual inputs (atmosperic file and obstacle file for each tid)\n",
    "        \n",
    "        # Must use subprocess as a way of wrapping/calling the python script becuase that script uses multiprocessing\n",
    "        # and other methods seem to break\n",
    "        # \"<TID>\" in \"--output_filename_pattern\" will replaces with actual TIDs inside the script with parallel processing\n",
    "        \n",
    "        # subprocess.run([\"python\", script_path,\n",
    "        #             \"--inputs_dir\", dest_dir, \\\n",
    "        #             \"--index_file\", \"01 Bergey Turbine Data/bergey_sites.csv\", \\\n",
    "        #             \"--output_filename_pattern\", \\\n",
    "        #                 \"03 Model Outputs/%s_%s_%s_%s_%s.csv.bz2\" % (site_type, model_type, \"<TID>\", wind_source, obstacle_mode), \\\n",
    "        #             \"--procs\", \"8\"],\n",
    "        #            #stdout=subprocess.DEVNULL, # This addition suppresses entire (lengthy) output\n",
    "        #            cwd=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864298eb-601e-4180-821a-012e5d6199f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one case and confirm that there is indeed difference between\n",
    "# bldgsonly and bldgsandtrees\n",
    "\n",
    "# f1 = \"03 Model Outputs/bergey_anl_t034_wtk_bc_bldgsonly.csv.bz2\"\n",
    "# df1 = pd.read_csv(f1)\n",
    "# df1\n",
    "\n",
    "# f2 = \"03 Model Outputs/bergey_anl_t034_wtk_bc_bldgsandtrees.csv.bz2\"\n",
    "# df2 = pd.read_csv(f2)\n",
    "# df2\n",
    "\n",
    "# Looking for non-zero mean here to see the difference between two outputs\n",
    "# (df2[\"ws-adjusted\"] - df1[\"ws-adjusted\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71835cca-b571-4e78-9515-7a3f60fad83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick vis of data in produced files\n",
    "\n",
    "# for f in glob.iglob(\"%s/*\" % dest_dir):\n",
    "#     df = pd.read_csv(f)\n",
    "#     fig = plt.gcf()\n",
    "#     fig.set_size_inches(2.5,2.5)\n",
    "#     sns.scatterplot(x=df[\"ws\"], \\\n",
    "#                     y=df[\"ws-adjusted\"], alpha=0.2).set(title=os.path.basename(f));\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76d4a6-854d-43ea-b66f-24f576b2dc16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
